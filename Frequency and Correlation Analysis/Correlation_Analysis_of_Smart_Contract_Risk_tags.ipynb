{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of Correlation Analysis in Smart Contract Security Data\n",
        "\n",
        "Welcome to the advanced section of our analysis series, where we focus on implementing correlation analysis for binary data using Python. In this notebook, we'll dive into calculating both the Phi coefficient and the Point-Biserial correlation, visualizing the results, and interpreting what these correlations tell us about the relationships between different risk tags in smart contract data.\n",
        "\n",
        "## Objective\n",
        "Our goal is to enhance your ability to perform and understand advanced statistical analyses, preparing you for data-driven decision-making in cybersecurity or any field requiring detailed data insight.\n",
        "\n",
        "Before you begin, ensure you have a basic understanding of Python programming and familiarity with libraries such as pandas, matplotlib, and seaborn. If you're ready, let's start by setting up our environment and loading the data!\n"
      ],
      "metadata": {
        "id": "pxQuVWv7YkwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import libraries"
      ],
      "metadata": {
        "id": "aIYqn6nCYvST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "\n",
        "# Ensure plots are displayed inline in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "HkiRjYs6Yv1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Download the dataset"
      ],
      "metadata": {
        "id": "Hc13c8B8Yz4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step would download the Webacy Smart Contract Risk dataset. If you have your own dataset, then please add it to colab's environment."
      ],
      "metadata": {
        "id": "VLCinTKx_VqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1andAuermOWqVXfhsh_AQ3Db93D3BIqgx"
      ],
      "metadata": {
        "id": "d3D84FPQY3ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Setup complete. Imported pandas, seaborn, and matplotlib. Downloaded Webacy risk dataset.\")"
      ],
      "metadata": {
        "id": "rQo-Sp2lY6zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Load the Data Section\n",
        "\n",
        "Now even though we have downloaded the dataset, we still need to load it into our Python environment. For this we will utilize the Pandas library."
      ],
      "metadata": {
        "id": "icYIrcZNY_aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "\n",
        "df = pd.read_excel('/path/to/data')\n",
        "\n",
        "# Display the first five rows of the dataframe\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SD1rsI8AZACs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Correlation\n",
        "\n",
        "To calculate the Phi coefficient, which is suitable for pairs of binary variables, we first need to establish a function that can handle this calculation:"
      ],
      "metadata": {
        "id": "noBnsUbpZC7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def phi_coefficient(x, y):\n",
        "    \"\"\"Calculate the Phi coefficient for two binary variables.\"\"\"\n",
        "    # Create a contingency table\n",
        "    contingency_table = pd.crosstab(x, y)\n",
        "    # Calculate the phi coefficient from the contingency table\n",
        "    chi2 = scipy.stats.chi2_contingency(contingency_table, correction=False)[0]\n",
        "    n = np.sum(np.sum(contingency_table))\n",
        "    phi = np.sqrt(chi2 / n)\n",
        "    return phi\n",
        "\n",
        "# Example calculation between two risk tags\n",
        "phi = phi_coefficient(df['Is_honeypot'], df['anti_whale_modifiable'])\n",
        "print(f\"Phi Coefficient between 'Is_honeypot' and 'anti_whale_modifiable': {phi}\")"
      ],
      "metadata": {
        "id": "HqLV59ooZeUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phi value close to 0 indicates no correlation between the two columns.\n",
        "\n",
        "**Note:** Phi values range from -1 to 1. A negative value of Phi indicates that the variables are inversely related, or when one variable increases, the other decreases. On the other hand, positive values indicate that when one variable increases, so does the other."
      ],
      "metadata": {
        "id": "Vh8NU_kNZ4F1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now define the risk columns of our dataset."
      ],
      "metadata": {
        "id": "Qt0CuDYLbDYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "risk_columns = ['Is_closed_source', 'hidden_owner', 'anti_whale_modifiable',\n",
        "       'Is_anti_whale', 'Is_honeypot', 'buy_tax', 'sell_tax',\n",
        "       'slippage_modifiable', 'Is_blacklisted', 'can_take_back_ownership',\n",
        "       'owner_change_balance', 'is_airdrop_scam', 'selfdestruct', 'trust_list',\n",
        "       'is_whitelisted', 'is_fake_token', 'illegal_unicode', 'exploitation',\n",
        "       'bad_contract', 'reusing_state_variable', 'encode_packed_collision',\n",
        "       'encode_packed_parameters', 'centralized_risk_medium',\n",
        "       'centralized_risk_high', 'centralized_risk_low', 'event_setter',\n",
        "       'external_dependencies', 'immutable_states',\n",
        "       'reentrancy_without_eth_transfer', 'incorrect_inheritance_order',\n",
        "       'shadowing_local', 'events_maths']"
      ],
      "metadata": {
        "id": "GGiaIQKtZusf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will calculate the phi coefficient for all the columns"
      ],
      "metadata": {
        "id": "7Z4PfWUpbJdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "risk_df = df[risk_columns]\n",
        "\n",
        "# Create a DataFrame to store Phi coefficients\n",
        "phi_matrix = pd.DataFrame(index=risk_df.columns, columns=risk_df.columns)\n",
        "\n",
        "# Calculate Phi coefficient for each pair of binary variables\n",
        "for var1 in risk_df.columns:\n",
        "    for var2 in risk_df.columns:\n",
        "        phi_matrix.loc[var1, var2] = phi_coefficient(risk_df[var1], risk_df[var2])\n",
        "\n",
        "print(\"Phi coefficients calculated for all pairs of variables:\")\n",
        "phi_matrix\n"
      ],
      "metadata": {
        "id": "T8u2SJD5ZRab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now even though we have the full correlation matrix in front of us, it is very difficult to visualize. One thing that we can do is only display those correlations where value is significantly positive or negative.\n",
        "\n",
        "But a much better way is to visualize this matrix as a heatmap."
      ],
      "metadata": {
        "id": "La1_E9R2bgbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the size of the plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Creating a heatmap\n",
        "sns.heatmap(phi_matrix.astype(float), annot=False, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Heatmap of Phi Coefficients Between Risk Tags')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WFlRMS5ybasO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can experiment with a variety of versions of this heatmap to improve visibility of the trends"
      ],
      "metadata": {
        "id": "HSJMCROqcENc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9IObHSaFnkD"
      },
      "outputs": [],
      "source": [
        "# Setting a figure shape\n",
        "plt.figure(figsize=(19, 12))\n",
        "\n",
        "# Creating a Filtered Heatmap\n",
        "threshold=0.2 # set threshold\n",
        "\n",
        "phi_matrix = phi_matrix.astype(float)\n",
        "\n",
        "# Create mask for low correlations and diagonal\n",
        "mask = np.abs(phi_matrix) < threshold\n",
        "mask = mask.to_numpy()\n",
        "np.fill_diagonal(mask, True)  # Hide diagonal\n",
        "\n",
        "# Plot heatmap with improved formatting\n",
        "sns.heatmap(phi_matrix,\n",
        "            mask=mask,\n",
        "            cmap='RdBu_r',\n",
        "            vmin=-1,\n",
        "            vmax=1,\n",
        "            center=0,\n",
        "            annot=True,\n",
        "            fmt='.1f',\n",
        "            square=True,\n",
        "            cbar_kws={'label': 'Phi Coefficient'})\n",
        "\n",
        "plt.title(f'Correlation Heatmap (|φ| > {threshold})')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Correlations Table\n",
        "# Get upper triangle\n",
        "upper_tri = phi_matrix.where(np.triu(np.ones(phi_matrix.shape), k=1).astype(bool))\n",
        "stacked_corrs = upper_tri.stack()\n",
        "strong_corrs = stacked_corrs[np.abs(stacked_corrs) > threshold]\n",
        "strong_corrs = strong_corrs.sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nTop Positive Correlations:\")\n",
        "print(strong_corrs[strong_corrs > 0].head(10))\n",
        "print(\"\\nTop Negative Correlations:\")\n",
        "print(strong_corrs[strong_corrs < 0].head(10))\n",
        "\n"
      ],
      "metadata": {
        "id": "jOd07uJ8oVPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also use a network graph. Would recommend reducing the number of features here before using a network graph."
      ],
      "metadata": {
        "id": "UR6iLCzLpEo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified Network Graph\n",
        "plt.figure(figsize=(15, 15))\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add edges for strong correlations\n",
        "for i in range(len(phi_matrix.columns)):\n",
        "    for j in range(i + 1, len(phi_matrix.columns)):\n",
        "        corr = phi_matrix.iloc[i, j]\n",
        "        if abs(corr) > threshold:\n",
        "            G.add_edge(phi_matrix.columns[i],\n",
        "                      phi_matrix.columns[j],\n",
        "                      weight=abs(corr))\n",
        "\n",
        "# Draw network\n",
        "pos = nx.spring_layout(G, k=1, iterations=50)\n",
        "\n",
        "# Draw nodes and labels\n",
        "nx.draw_networkx_nodes(G, pos, node_size=2000, node_color='lightblue', alpha=0.6)\n",
        "\n",
        "# Draw edges with width proportional to correlation strength\n",
        "edge_weights = [G[u][v]['weight'] * 5 for u, v in G.edges()]\n",
        "nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.5)\n",
        "\n",
        "# Add labels\n",
        "nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')\n",
        "\n",
        "plt.title('Network of Strong Correlations')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FzahdBLEoXvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubp2VdzQo9rY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}